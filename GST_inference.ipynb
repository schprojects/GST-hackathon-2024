{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Code to load the selected model (Voting Classifer with CatBoost, XG Boost and Light GBM) and run inference**"
      ],
      "metadata": {
        "id": "j6mtG21jvSMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install catboost"
      ],
      "metadata": {
        "id": "Edla8gqDvqgS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6AyEiRD66zJ9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Path to data for inference - place holder change accordingly**"
      ],
      "metadata": {
        "id": "mi_LDIpev_4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the path to the data which needs inference\n",
        "INFERENCE_DATA_PATH = \"/content/X_Test_Data_Input.csv\"\n",
        "# e.g : INFERENCE_DATA_PATH = \"/content/GST/inference_data\""
      ],
      "metadata": {
        "id": "SnQWE3hYwKR0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the data**"
      ],
      "metadata": {
        "id": "Dh43OU_uwjiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_data = pd.read_csv(INFERENCE_DATA_PATH)"
      ],
      "metadata": {
        "id": "a8OylZQzwmdr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare the data for inference (match schema of trained model)**"
      ],
      "metadata": {
        "id": "wK4-NVVvygB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_columns = ['Column0', 'Column1', 'Column2', 'Column3', 'Column4', 'Column5',\n",
        "       'Column6', 'Column7', 'Column8', 'Column10', 'Column11', 'Column12',\n",
        "       'Column13', 'Column15', 'Column17', 'Column18', 'Column19', 'Column20',\n",
        "       'Column21', 'target', 'Column16_0.0', 'Column16_1.0', 'Column16_2.0']"
      ],
      "metadata": {
        "id": "dBzH5yvSxoVp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing cleanup so that the data schema is matched to the trained model\n",
        "\n",
        "# Dropping the columns not needed\n",
        "inference_data.drop(['ID'], axis=1, inplace=True)\n",
        "inference_data.shape\n",
        "\n",
        "inference_data.drop(['Column9', 'Column14'], axis=1, inplace = True)\n",
        "\n",
        "# One-hot encoding the 'Color' column\n",
        "inference_data = pd.get_dummies(inference_data, columns=['Column16'])\n",
        "\n",
        "# Align with the training data columns (fill missing with zeros)\n",
        "inference_data = inference_data.reindex(columns=trained_model_columns, fill_value=0)\n",
        "\n",
        "print(\"Shape after:\", inference_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTI37t_YwLR_",
        "outputId": "9aa3c573-0256-4731-d444-1646c3b0cd64"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after: (210733, 23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split target and features\n",
        "X = inference_data.loc[:, inference_data.columns != 'target']\n",
        "# y_expected = inference_data['target']"
      ],
      "metadata": {
        "id": "tB5y6wVgzQ-1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the trained model for inference**"
      ],
      "metadata": {
        "id": "uqAdpxVMy1GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model for inference using pickle\n",
        "with open('GST_Model.pkl', 'rb') as read_model:\n",
        "    loaded_GST_model = pickle.load(read_model)"
      ],
      "metadata": {
        "id": "r28av8PfugNG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make predictions**"
      ],
      "metadata": {
        "id": "qWJzKvBD0QZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the data\n",
        "y_preds = loaded_GST_model.predict(X)\n",
        "\n",
        "#Evaluate the performance\n",
        "# accuracy = accuracy_score(y_test, y_pred_loaded)\n",
        "# print(f\"Training -----> Accuracy of Voting Classifier: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "YyMHyKARy5fQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print predictions\n",
        "print(\"predictions\")\n",
        "print(y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcFAv81Xzxyb",
        "outputId": "f2c9e5b6-e929-4abb-fb66-7613f2f095bd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions\n",
            "[0 0 0 ... 1 0 0]\n"
          ]
        }
      ]
    }
  ]
}